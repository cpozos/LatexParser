{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisitos del proyecto\n",
    "Debe contener lo siguiente:\n",
    "\n",
    "1. Explicación del problema a resolver (cuáles son los inputs y porqué, cual es la salida y porqué, cómo se obtuvieron y de dónde)\n",
    "2. Análisis de los datos (histogramas, visualización de una muestra tanto la entrada como la salida, normalización encaso de ser necesaria)\n",
    "3. Separación de los datos (seleccionar un porcentaje para cada conjunto)\n",
    "4. Definición, Entrenamiento y Evaluación de la red neuronal\n",
    "5. Inferencia (usando los datos de prueba)\n",
    "6. Comentario: explicar porqué se obtuvieron esos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Explicación del problema\n",
    "_____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema a resolver es la traducción de imágenes con ecuaciones matemáticas a una secuencia de símbolos que $\\LaTeX$ utiliza para generar ecuaciones matemáticas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![traduccion](images/diag2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello se empleará el modelo *Sequence-to-Sequence* (S2S), este modelo es un caso especial de una familia general de modelos llamados: *encoder-decoder models*, que son una composición de dos modelos: *encoder* y *decoder*, que suelen ser entrenados en conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![encoder-decoder](images/encoder-decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo encoder es usualmente una red neuronal convolucional (CNN) que transforma imágenes en un grupo de mapas de características, o una representación $(\\Phi)$, que es generalmente un vector. El decoder por otro lado, es usualmente una red enuronal recurrente (RNN) que tiene como meta tomar la representación ($\\Phi$) de la entrada y producir la salida deseada. A partir de lo anterior, se puede definir a los modelos S2S como modelos encoder-decoder, en los que el encoder y el decoder son modelos de secuencia y las entradas y salidas son secuencias, posiblemente de diferentes longitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.I Entrada y salida (Contexto a la solución del problema)   \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Si se define a una imagen de una ecuación matemática generada con LaTeX como: $(x,y)$, en donde $x \\in \\mathbb{R}^{H \\times W}$ es una imagen en escala de grises de altura $H$ y ancho $W$, $y = [y_1,...y_T]$ es una secuancia de $T$ símbolos que definen la fórmula matemática de la imagen. La meta es obtener la salida $y$ a partir de la entrada $x$, es decir, encontrar una función $f: f(x) \\longrightarrow y$.  \n",
    "\n",
    "Dado un conjunto de imágenes $(x_i,y_i)\\,i \\in \\{1,...,N\\}$, se puede usar entrenamiento supervisado para construir una función de predicción de secuencia $f'$ que aproxime a $f$, $f': f'(x) \\longrightarrow y'$, para predecir una secuencia de $LaTeX$ $y'$ que reconstruya la imagen $x$. La evaluación se puede realizar mediante la comparación de $y'$ y $y$, y entre la imagen $x'$ creada a partir de $y'$, con la original $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.II Obtención de los datos\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se obtuvieron de la página [LSTMVis](http://lstm.seas.harvard.edu/), una herramienta de análisis visual para redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para descargar el conjunto de datos:  \n",
    "- Estar en la carpeta de images: `cd src/data/sets/raw/images`\n",
    "- Descargar el dataset: `sudo tar -zxvf formula_images_processed.tar.gz`\n",
    "- Comando sugerido para copiar los datos .png una vez descomprimidos a la carpeta de images:  \n",
    "`find /src/data/sets/raw/images/formula_images_processed/ -name \"*.png\" -exec cp -uf \"{}\" /src/data/sets/raw/images/ \\;`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**  \n",
    "[1] Delip Rao & Brian McMahan, *Natural Language Processing with PyTorch*, (2019) Chapter 8.  \n",
    "[2] [Translating Math Formula Images to LaTeX Sequences Using Deep Neural Networks with Sequence-level Training](https://arxiv.org/pdf/1908.11415.pdf)  \n",
    "[3] [Image-to-Markup Generation with Coarse-to-Fine Attention](http://lstm.seas.harvard.edu/latex/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. & III. Análisis de los datos y Separación de datos\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies \n",
    "import random\n",
    "import statistics\n",
    "from functools import partial\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TORCH\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT\n",
    "from architecture import *\n",
    "\n",
    "from data import DataBuilder\n",
    "\n",
    "from utilities.dataloaders import *\n",
    "from utilities.training import *\n",
    "from utilities.latex_gen import *\n",
    "\n",
    "from utilities.tensor import *\n",
    "from utilities.persistance import *\n",
    "from utilities.logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_workers = 1 #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "División de los datos en conjuntos train, validation y test / hiperparámetros de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************************************\n",
    "# **********************  Hyper parameters  **************************\n",
    "# ********************************************************************\n",
    "    \n",
    "# data\n",
    "num_data_train = 100000  # max\n",
    "num_data_val = 20000  # max\n",
    "num_data_test = 2000  # max\n",
    "batch_size = 10 #50\n",
    "    \n",
    "# training\n",
    "epochs = 5  # default 10\n",
    "learning_rate = 3e-4 #default 3e-4\n",
    "drop_out = 0.2 # default 0.2\n",
    "clip = 2 #default 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de los datos:  \n",
    "(Para ver los códigos de la obtención de datos: `/src/data/`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++ Información sobre el número de datos: ++++++++\n",
      "Número de datos train: 75275\n",
      "Número de datos validation: 8370\n",
      "Número de datos test: 2000\n"
     ]
    }
   ],
   "source": [
    "# ********************************************************************\n",
    "# **********************  Get data  **********************************\n",
    "# ********************************************************************\n",
    "data_builder = DataBuilder()\n",
    "\n",
    "vocabulary = data_builder.get_vocabulary()\n",
    "\n",
    "force = True\n",
    "train_dataset = data_builder.get_dataset_for('train', max_count=num_data_train, force=force)\n",
    "valid_dataset = data_builder.get_dataset_for('validate', max_count=num_data_val, force=force)\n",
    "test_dataset = data_builder.get_dataset_for('test', max_count=num_data_test, force=force)\n",
    "\n",
    "num_data_train = len(train_dataset)\n",
    "num_data_val = len(valid_dataset)\n",
    "num_data_test = len(test_dataset)\n",
    "\n",
    "print(\"+\"*8+\" Información sobre el número de datos: \"+\"+\"*8)\n",
    "print(\"Número de datos train:\", num_data_train)\n",
    "print(\"Número de datos validation:\", num_data_val)\n",
    "print(\"Número de datos test:\", num_data_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de dos datos de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABlCAYAAABUdbijAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4SUlEQVR4nO29eXBc133v+TndABq9oNFYuhtbY2ti4b6Kok1Rm6WSTWuLbSV5GdtJ5VUSp2Y89uRN5TmTqqma/17VTL3x+2NmEtd7b+zMyHZevDxJlj2kFtKiTMkiJYogSIIACGJfG0sDvW93/gDO8UWzAYIACDTo+63qAvr2XX73LL/z24/QNA0DBgwYMLDzYNpuAgwYMGDAwPpgMHADBgwY2KEwGLgBAwYM7FAYDNyAAQMGdigMBm7AgAEDOxQGAzdgwICBHYoNMXAhxOeFELeEEL1CiO9sFlEGDBgwYODeEOuNAxdCmIFu4FlgGLgE/CtN025sHnkGDBgwYGAlbEQCPw70aprWp2laAvgx8NLmkGXAgAEDBu6Fgg1cWwsM6b4PA4+udkFlZaXW2Ni4gUcaMGDAwO8fPv7444Cmae7s4xth4CLHsbvsMUKIvwT+EqC+vp7Lly9v4JHbj5VMTkLkag4DBnY+sse8Mda3HkKIgVzHN2JCGQZ8uu91wGj2SZqmfU/TtGOaph1zu+9aQAwYMGDAwDqxEQn8EtAihGgCRoA/Bv5kU6jKwlodrQ9SMthI0a8HUTBMvutK0tFaj+t/kzAkrs3F/fbRVtKw0u9ruZcxLrYf62bgmqalhBD/HXAGMAP/WdO065tGWRYymYx87rLjQgj1MWAg3/CwVfs0mHd+YSMSOJqm/RL45SbRkuv+d/3daht0vk7AfKXr9wX3Goe/D/3zsDLz9fTddrXBhhj4VkA/SFZqpO1qvFQqRTqdpqCggIKCrW/Kh3UC7RRkMhk0TcNkWnQl5eoHTdN2bP8kk0kSiQRCCEwmEyaTicLCwh37PuuB7GNYvjjL/7db+887Bq5f/fQS92p2w+xJshm2xdVWYdmpyWSSdDqtJnA+SF0r0bAabfdaCIyFIjfk+FyJSes1x9XGZ/bxzWznjTwrk8mQSCTU98LCQiWo5Hqfh3V8ZPMk+VfPxLerDfKOgUvoG2R2dpaRkRHm5+cZGRlR9vDi4mJqampwOBw0NzdjtVofCC3yeUIIkskkr7/+Oj09PdTU1OByudi3bx9+v3/ZZNZ3ZDqdJplM3tXp8t6rMVf9vYQQmM3mZZNI0zRSqZSSkuQxeVzTNAoLCzGZTKTTaTRNI51OK83BbDara/Xvm0wmAdQ9t0PDyHfo2yzXxNX3cTqdVv0n+zuTyai+e1CSrexvSQNAQUGBkqj1z0wmk6RSKfVbMBhkcnKSrq4uzp07R0NDA88//zylpaVUVVUte5eHlXnr55VErgX5996EkmuVg8UGDIVCDAwMMD4+TmdnpxqIDoeDffv2UVlZSW1tLcXFxavee72SuJ6eRCLBBx98wHvvvcehQ4doaGjA6/UqBp7JZJZ1uDwWj8eXMXf5u5xceujplP/LexYWFiqmK++vZwL6ZyaTSTKZDGazGZPJpCaxnKiZTIaioiLMZvOydpKSl2Q4JpNJnbMSnQ8r7rW4rgWyLyTjlPdNp9MkEglMJhMFBQWbEp2Si17Z13ppWvar/vxUKkUsFlMmwUgkwszMDB0dHbz66qscPnyYAwcOUF1djcfjuYuBP4zMPJeJJFcEj5zbW90GecPAJfQDKhAIMDExQXd3Nx988IGyOUtEIhGuXLmCxWLhzp07lJWVcfLkSdxut5osG2lI2TEmk4loNMr58+cZGhpieHiYwsJCWltbOXbsGDU1NTk7TkpY/f39vPHGG0QiEeLx+DKJTErH2dfq76FfFI4cOcLp06eJxWJMTk4yOjrKhQsXKCsr45VXXsHlciGEIBKJ8NprrxEIBHjhhRdoamrizp07TE5O0t3dzdDQEA0NDTQ0NFBXV8euXbvUJO/p6eFnP/sZNpuN/fv3U1FRwf79+7FarWqx0Uufv2/IZDJEo1GuXbtGJBLB4/Fgs9nwer04HA513tTUFDMzM1y/fp2rV69y9OhRPv/5z6u+HB4e5o033sDlcnH69GlKSkqwWCwbnvyZTEYxnnA4zI0bN5idneXatWskk0n27NlDeXk5e/bsoaKigkQiQTKZ5MyZM3z00Uf4/X6am5txuVw0NTVx5MgRXnjhBQoLC3nnnXdoamrC5/NRUlKyTOt7mBh3MpkkmUwyODjI0NCQ0nyTySTRaBSHw0FNTQ02m42qqioKCgq2pQ3yioFn2xNnZmbo6uri2rVrfPjhhzidThoaGpQEGo1GuXXrFqlUik8++YTy8nKam5spLS1VauBGGlXPlJPJJOfOnaOjo4NoNEpBQQF+v5/jx48ryTeXeUQOgh//+MdMT08TDAZJpVJKwi0pKVlVfU6lUkrCFkLwJ3/yJzz33HOEQiH6+/u5evUq3/ve92hsbOTZZ5+lpKSEgoICotEov/rVr+jt7eXQoUPU19czODhId3c3b7/9Nh9//DHHjx/nkUceIZPJ4Pf7lQTW3d3N9773PcrKyvjKV75CU1MTra2tyxj4djtvthOZTIZIJMInn3zC9PS0YoQlJSXLGPj09DR9fX2cPXuWf/mXf+FrX/san/vc55QWNTo6yj//8z9TV1fHiRMnKCoqoqioaFOEDil4RCIRbt68ycDAAK+99hqRSITPf/7zNDU1UVNTQ3l5uWJK58+f5/vf/z6PP/44jz32GMeOHePIkSMkEgnm5+e5ffs2Z8+eJRAI8Pzzz1NcXLxhevMVsk1u377Nb3/7W4qKirBYLEQiEWZnZ/F4PBw+fBi3243H41HXbTUT33YGnkvlk3bhnp4e3njjDTKZDPX19dTW1nL8+HGlbiaTSWZmZpienubNN99kdnaW69evk06naW1tpaysbEW79Gr06Bl3KpViYmKCqakphoaGmJiY4KmnnsLv99PS0rJMgpbX6M0ehYWF+Hw+XnnlFfr6+vj5z39OMpnE7XbjdDo5efIkFRUV6jr57nKRGhgYYHh4mImJCYaHh0kmk2rxGhoaYnp6GqvVis1mo6CggEwmw8jICGNjY0xNTTE7O6vMNzU1NRQWFtLR0UFhYSGJRILZ2VkikQiwyHBu3LjBrVu3iMViWCwWdu/ejc/nw2KxqHeS77nTsBkhqNI8FY1G6ejoUNpYJBKhqalp2TNmZ2cZHBwkEongcDiwWq2YzWai0SiBQIDBwUECgQBOp1OZq9ZLd7bZUaK4uJjW1lYsFgsOh4NEIkEoFGJ2dlb5Zfr6+hgZGWF0dFSNzYMHD1JbW4umaZSWlrJ37151/uzsLB999BE1NTUcPHgQm822bNHYKVjJ3JRKpXj//ff59NNPmZycZHJykubmZtra2picnGRmZobR0VEGBgbw+XxYrVbKysqU5n+/PGcj2HYGng3JxNLpNJ2dnbz66qscOnSI06dPs2/fPl588UWKioqA35koenp6+OEPf8jQ0BAff/wx4XAYr9dLeXn5XaFea4HsWOn4Gx4eZnh4WA30U6dO8fzzzyszzUqTR5pImpqa+Iu/+AsuXbrEL37xCyKRCNXV1fh8Pr7+9a+za9euu5ya0sH43nvv8eGHH3Lp0iW6u7tJJpNKsrp9+zYTExPYbDYleafTafr7+xkYGGBsbIzp6WlisRiZTIbGxkZ8Ph/nz5/HYrEQi8WYmpoiHA4jhGBycpL333+frq4uotEoVquVw4cPU11dfRcD/31GJpMhHA7z29/+lp6eHlwuF/F4nCNHjqhzNE1jenqa27dvEwqFKC0txWazYTabCYVC9PT00NfXx8TEBGVlZYqB3+9isprzFFBmMKfTSWlpKfPz88zPzxMIBJSPpKuri08//ZTBwUESiQTV1dVKI9A0jfLyciorKwmFQuq9zp8/T2NjI21tbdjtdmXa3OmaWTKZJBaLcebMGf7pn/6JiooKysvLqa+vp6WlBZPJRHd3N/39/bz99tu0tbXR2tpKfX09LpdLMXDYGiEnrxh4Ls+u2WxWH2lv05sqpJTrdruV02VoaIhIJLIiY10rNE0jFovR0dFBf38/JSUl+P1+nE6nkpakvTEX/fJYKpVibm6OhYUF5VT0eDxUVVVRUlKCzWZbdp2UwE0mE1VVVbS1tRGNRgmHw9TX1wMQi8UYHx8nFApRVVWFx+OhoKBAaQyTk5MUFxdTVlamJHPpjEwkEiwsLFBaWkp7e7tSAWdmZrh69SoLCwvs3buX1tZW7Ha7msg7zc6ZyzG+WrifHquFyZnNZlwuFy+++CITExMcOXIEj8eDy+VaZsIIBoOMj49jMpmoq6tTjDoajTI6OkowGKS0tBSn0wks93esROta6dYLIVLQiEQixGIxamtraWpqwm63o2kaAwMDXL16FYvFwqFDh6irq8NisSxzUgKUlZXx6KOPMj8/z9DQYiHSUChESUnJXY71tdCfD8h2QA4NDTE+Ps74+DixWIzm5mYee+wxdu/eTUVFhQoCsFgs/PrXvyYejzM8PExBQQF79uxR99wq5BUDz4bZbMZisaj402zpTzJzi8WCLFMrJ0YwGFxmr10PNE0jFApx9uxZbt++jd/vVx1pNptVBIlktvrr9MwuHo8zPj5OIBAgnU5TVFREY2Mjzc3Nyna60qD3+/24XC4lBR04cAAhBAsLC/T29lJUVER7ezuNjY0UFRWRTCaVBO5wOCguLqawsFCFDUoGMj09jdvt5rHHHqO6uhohBKOjo7z11lvU1tbywgsv0NbWhsvlwmKxLAs93GmQZg9gXY5tfd9Ircrr9fK3f/u3ZDIZNTal9CXbampqit7eXnw+H3v37qWmpkb13a1bt5iamsLr9eJ2u5XmqadzNQEk29SXDb1QYbFYKCgoIBgMEg6H2bNnD4cOHVIaakdHB2fPnuXpp5/m8ccfp729HZvNpt5Dvnd1dTVf+tKX6Ozs5Lvf/S6BQIDZ2VlKS0uVQ3OnQa+hZzIZOjs7uXr1Krdv3yYcDvPII4/wN3/zN8qJWVdXx6FDh3A4HHz/+98nHo9z8+ZNEokEjz/++LJIlK0QePJyNkrJuqWlhRdffJG6ujoaGxspKSlhbGxMOXsKCgqw2WwUFhZSUVHB/Pw8g4ODRKNRZTbIDunTP0OP7N+kGScej7OwsEAoFKK8vJy6urqc8ebZEpt+ciUSCWWPTqfTFBYW4nK5KCsrw2w2q0GkaRrRaJRUKoXNZsNisSjGYLFYsNlsymkk7dcOhwOLxUJxcTFCCNLpNDMzM+o3s9nM0NAQFouFiooKrFYr4XBYMZtkMsnQ0BBDQ0MMDAxQVlZGbW0t7e3t1NfXK00jV2hjviJXGJ4+bFN/Tvbim32PXJNQxtdLU568v/xI5isXSq/Xi9VqVc7qeDxOIBAgGo3idruxWCx0dHTg8XjYs2fPsn6WkMKCnjFnjzkZw623pUs/0dTUlLo+nU4TjUbp7OxUzrrKykoaGxvZvXs3lZWVy2y4cg5ZLBalaaRSKRXeazKZ2LVr133ZwlcKG95s5DLp5OIDsv1GRkaUqdLtdqs5pF9QTSaTyj2R1xQXF6sIs9W0t81GXjJwaTI5ffo0zzzzDIlEQnl/P/30UwoLC6msrMThcOD3+ykuLsbv9wPw8ccfKztfKpWiqKjoviUD2diRSISFhQUmJyeZnZ2lubmZgwcPUlZWBqzs0NPHgwOEw2G6u7u5c+eOYs4+n4/6+npl9pALxtjYGPPz89TX1yvJzGQyYbFYcDqdWK1WJUX39/fj9Xqx2+1qoEkJfGhoiPb2dkpKSrh48SLvvfcee/bswePxKPNKOp0mGAzS2dnJxYsXSaVS7N69myNHjvDFL35RRcjsNOdULsgJmEgkVHsDWK1WZd/XY6XFXjowAWXTzoY0J8zOztLX10djY+OyvltYWKCnpwebzcbu3btJpVK8+uqruN1uvvnNb1JTU6MkPr0WJx3YgIoAkUilUio6Sm+Si0QidHZ2qrEn47unpqZ45513GBwcJJlMsn//fp588km+8IUvKJOZ/l1kxFRLSwuTk5NKKHn//fcZHR3F6/Vis9mUMLIWW7hk9tl5EJuF1RzDEnJcJxIJYrEYV65c4Ve/+hV1dXXs3buXysrKu9LphRBUVFTw9NNPMzAwwDvvvMPMzAwLCwtUVlZuaWROXjJwiXA4zMzMDMFgkImJCWKxGHNzc2qAzc/PEw6HlSQwMTGhpBC4/5U9O2xwfHycsbExFfLncrmorKxcNuFzSff64zK2enZ2lvn5eWAxJbm8vJyKigo1CWU0yNjYGAsLC4p5S+m7tLSU6upqrFarsqdLDSEQCFBcXMz169dZWFhgenqa+fl5ZmZmlL2uuLhY2fQlA5ubm1MaS3l5OVarFafTucz2fT9RJw9aklrv86VfQDKuSCSislJdLhclJSVUVlZSWVl5F+ORjDEajTI5OUk8Hmdubg6A8vJyiouL8fl82O32ZQt2LBYjEomQyWQIhUJMTU0xMDDAtWvXuH37NsFgkEQiwfT0NCaTieLiYqVNSsYtx3g8HmdgYIC5uTn1jjU1NVRXVxOJRAiHwywsLDAzM4PFYsHlcuF0OqmvryedTi8TaGRbFBQUKM21tLQUu91OTU0NxcXFy5hedrtLjdBut6sggkQisaG+f1DMbj2msmQySTwex2q1UllZic1mU4u/FMqkliNNUzJmfCtt3xJ5ycBlQ9y8eZNz584xMDCgVMwDBw4oE0o4HObWrVsqRlUmytjtduWAWWujStulXLVDoRAXLlzgzp07hEIhioqK8Pv97Nu37656ENkDRUrNcoAHg0F6enoYHV3c78LhcLB7925aW1spKCggkUhw48YNFcoVCoXweDw0NDSoCeV0Otm1axfT09Ncv36dgYEBMpkMwWCQy5cvc/PmTTo6OojFYly/fp1QKEQwGKSkpIQXXngBv9+vGFE8HieRSHDz5k0ikQitra0888wz+Hw+Dhw4gMViUdLiTnNcZkPGbJ89e5Y7d+5w+fJlJiYmVARGY2MjVVVVnD59mueee04xNsnIw+Ewvb29DA4O8sYbbzA9Pa0ceH6/H6/Xy1/91V/R1tamGO/w8DBjY2MEAgEAhoeHuXjxIp2dnfz6179mZGSEgYEBCgoKmJmZwev18uSTT1JfX095eblaDJLJJN3d3YyNjfHTn/6Ua9euqcVXaqd9fX10dXUxNDTEzZs3cTqdNDY2sn//fr75zW8qJ9vw8LBaVC5evEhlZSWf+cxnePTRRzl48CB1dXXLpHp9v0vmJedIUVERDQ0NKiJKLob3i3yLWJEBB8lkEo/Hw969e6mqqqKwsFAtfpJ5y3Ei++n3joFnv6z+eyAQYGZmhjt37qiB5/F48Hq9eL1elQhhMpkIh8MEg0Hm5+dJJBKUlZUpyUgvid/vQMlkMsRiMWKxmBqgsvPWYg/WD85kMsnc3Bzz8/Ok02lSqRSTk5M4HA5MJhOxWIze3l4V561vD7kYSEdZJpNhZmZGhflZLBaKioqU5Gaz2WhpaVEqd1FREZWVlXg8HmKxGPF4XDFz2aa1tbVUV1fjdrtVElSu98unyabHSvbURCLB6OioikwaHx9XmXNycS8sLFRmsqGhIRXPK5nWwsKC0u5kxJPZbCaVSjE+Pq5syHozQCgUYnp6mnQ6jd1ux2q1Luuj8vJy9u7dq5yEsraI2+1WSWHz8/NEIhGGh4cZGRmhqKiIqqoqZmdnlUQvMyz1pRQSiQTDw8N4vV5SqRRms5ny8nJisRi7d+9WkUwul0v1e0VFhYqEkVjJaSqfU1ZWRjQaVWbGXEx8NYaWSqWUIBEOhzed+QkhVHz2/S4U+rm+FtPh/QiKm428kMDly8sB/dZbb/Hmm28SCAQYGxvjySef5Nvf/jYlJSVUVFSoRu3r6+Py5csEAgGVjHLs2DGam5upqanBYrEoqWE9MbaS2cqqg/F4nHg8rkKsVkK2oykcDnPz5k1mZmaIx+NMTk7yox/9SJlQ4vE4Z86cYXx8nGeeeUZJc3pI5jE/P09nZyczMzM0Nzdjt9tpb2+ntLRUZaG2trYCcO7cOebm5jh58iRNTU3KJPLEE08QDodVAlBhYaFSB/OVSa8FesejNBX8wz/8g0qGEkLwjW98QyWfmM1mXnvtNX7zm9/w6aefMjAwwMmTJ/niF79IMpkkHA6rHAO73c7JkycBuHPnDoFAgLfeeovBwUGVFCOZ78jICJ2dnQghaGlpwefz0dDQgNvtxufzUVlZid/vZ2xsjHPnzlFWVsbTTz+Ny+XCbreTSCTo6OhgfHycN998k7GxMb761a9y6NAhLly4wI0bN7h27Rq//OUveeSRR3jiiSeorq6mtbWV3t5ezp49i8PhIBaLUVZWxunTp0kmk7z00ktkMhnl27BarUqSXEvbSu3U5XKxf/9+JiYm6OnpYWZmhlAopCpzrjSG9IKUTHIaGRnh6tWry0pkbJQhSgm5tbWVL3zhCyqSba2Qkng8HieVSq143nYyboltZeDZklM4HCYcDjM2NkZ/fz8ATqdTFauyWq3Y7XbFGJ1Op4qjluq+3W7H6XTeVYEv2xG3lobXS2n3sxrrIx6kFC8Hg7zX/Py8snFLG3kwGKSoqIiysjJlZ8+WHmKxmFqwSkpKVNSIlOJKS0vx+XyYTCbq6+txOp2UlZWpaJWCggKKi4uVg3e1gb1WZq5vy1z1kzcKvSlnNeYgIePuZbbj8PAwJpMJu92Ox+OhpqZmWVRBKBSiuLgYu92uJmw8Hmd6eprZ2Vm12Em/xMzMDJFIZFlRMEmDdFJOTU2haYtZjG63m7q6OioqKpQWWV9fT2FhIQ0NDZSUlOByuZRGlslkmJ+fV9K12WymoqKC2tpaKioqcDgcJJNJFVnidrtVYaxIJKLs2lKKdDqdam7AouN2pbGcq32zHbrSZl9QUEAoFFIayWr9nks6l0Xe5HvK4xtlimazWWlW63WQ5qIjH4WbbWXg+rRxgCtXrnD9+nV+/etf09HRwenTp/mjP/ojGhoaVFp8LBZT0qjVauXQoUM4nc5l2YN2u33D8crSoQFQV1eH2WzG4XAsq/gHq4cPBoNBent7GRgYQAiB3W6nuroap9OJ3W5XKm8sFqOoqAin08mRI0d49tln8Xq9wO+cRrDImEZHR/nNb36jbOJ+v5+vfOUrikGbzWYVUvi5z32OdDqNw+FY5pCUjFtv41xr5MBq7QWoEM6VKhiuBzIrVV/+NvvZev9FMBjkzJkzyuYdjUb58z//c9ra2mhsbMRsNtPV1cX4+DgXL17ko48+4vTp0xw9ehSfb3Gf7sHBQc6cOcPc3BzV1dU0NTVx/PhxZaLQjy99id9UKkV3dzcXL16kvr6e9vZ2Tp06xdNPP01BQYEKf5XOz5dfflmNLekgk/08NjbG0aNHsVqt+P1+1cf68g1NTU0899xzioEfPXqUo0eP4vF4KC0tXdbP8hq9aXG9EUaaphGPx+nv76e0tFQ5hlfSdOUiLGGz2fB4PMzMzCzrw81g4HIsb4R5S5rzkWnrseUMPFfnyE6bnp7mzp07KlLAZrPR3NxMZWWlyibUOwtMJhNWq1VJFCaTCZvNhsPh2JSEEzkApMqpDw9aya6uP55IJJibm1MpyEVFRWpilZeXq3T2wsJCiouLicViOJ1O9Rssd4jKQZ4dFSNDCbMhwx2zca+BuR7JW34Ph8MqSmO9EzF7UZQJSTabDavVuup9JWMZHh5maGiIYDCoEpCKi4sJhUKYTCYCgQBTU1MkEgkKCgpwOBwq7hdQJjMhBG63m8rKSpxOJ5FIRDm0JCPVa2fSfJNIJLBYLJSXl+N2u6mqqrqLVovFkjOEUR99JOOu9fHIelitVpWQk0gklBNSzgF9W67GqNfDqGRby/jne/W3/hlms1kJW6WlpSQSibti9NcLuaBKzXw9uNccuZ/gCP3itdkLwrZK4HJAydCdK1eu8Itf/IKFhQU1oWQkBvyutoieqc3NzTE3N6fqLR85coRHHnmE8vJy9Yz1ZN/pa3i3trbicDhUCn12iVcJfUyr2WxW8b4yVK+2tpZXXnmF2tpaWltbKS4uVury1NQUN2/eVKqpPnxPb5Lxer2cOHFCZWVWVVUhhFhmQ8wOo1wLw96o5C3j2C9dusQHH3zAxMQEY2Njqq/WGu8rz9dLUMeOHaOlpYWDBw+yZ88edS/9ubJfZJndd999l8HBQdWHb775Ju+//75KqJGp7cePH+fkyZMcOXKEQ4cOKYba0NDAl7/8ZfUs2S/z8/PcvHmTkZERqqurcTgcStKVbeH3+/nMZz6jMmSrq6uVo1H/jtkam/zdarWq/Afpo5Bhe3KbM0BpVTIbWC50paWly7SC1dp6owxFP7/u517SnLd//37q6uo23Z4sNV4ZBrjee6z2TvoszlzP0P/+oCT5bWXg2WFKs7OzjI6OUlRUhN1uVx+9Kq5vjHQ6rezmUmqpqKhQ2W36Z8jn3A/0yR7SLCNX07XcSy+B61PoGxoaaGpqUgtTMBjE6/UyPj6+LHomV3ii3W6nrq5OSXalpaV3qafZ73uvwbPRwaVvj1AoxOTkJMPDw8p0dD9tBr9LHpGLkrQfywSa7GfrJ5pceGU9GCkhy3hqWBxDpaWluFwuqqqqqK6upr6+Xmks0l7s8/nuuncqlVL+CrvdTllZmdLMJC1lZWXU1dWpGjUysSZXtEyuPiooKFCRMvoxJx3qsh3koiLfSSbA3U+ewkax3kVAXicjdDYbcpFcjxlP/06rjdl8MLHkRRSKbAjp+d21axdtbW34/f5lg1eeJyWRQCDAhQsXGB0dpaKiQqm5+mQE6WSSg1syEhlhYjabcw4gIYRipr29vVgsFhUGKOnI1Xn6jL/Z2Vl6enoYHh5WDLyurk450aTNr6ioiK9//esEg0F2796tyo5m31cIwa5du/jDP/xDCgsLKSkpUXWK9bTI/+X7PshBpn+WyWTiscceo62tjWAwyNzc3LoYeLYG4fV6cblcuN1u9cxcEo9eso1EIgghOH78OF6vl1OnTi27vqqqSvkiZKlV/X1WclpnMhll5nvsscfw+XzLkj1MJhOPPvooe/bsUSGEufpTb5fO1T+5Shhomsb169c5e/YsHo9HRSxllzTeyk03ZOTYvfo2288SCAQYGBggEAjQ19e3bJxuNDNT+o0aGho4deqU8jusBTIqR/rAZAmD7MVXOnL1hd70Hz2PeJDzL68YuGSsTqcTn8+ndpfJVjWl7S0UCjE8PMzU1BR+v5/KykrFvOW9ZDy0tJPL+0hJZqXOlZNYiMWog4KCAmXrW81RA7+rKheLxZienmZhYQEhhHJUOhyOZe9lNpvZu3fvMlV9pTZyuVy4XK4Vn73W45sJvWmgtraW2tpaYrGYkhTXIs3kup88X8ZP6xOoVtI6JOSCX1NTQ2NjI4888gi1tbXqeukQ1I8t/U42uSaeNBPJTFiHw0F5efmySB4hFos+1dTUrPheKx3LFc2jNydlMhkCgQD9/f1UVVXR2NhIeXm5YtTyHJlwok+JX42GjWCt0mo2otEoU1NTDA8Pqxr++vfYCPRlCKSvYq2QjmYphK0W3y7fPdcinM3wV2ujjfRJXjDw7NVLMjopAWfbPAOBAB9++CFdXV0q9O7ZZ5/F7/er0qj9/f3MzMxw7tw5ent7+cpXvsJTTz2lGv3SpUu88cYbHDhwgJdeekklxGRPKJkMAosp0nKgrSQBwu82jY1EInR1dZHJZGhvb2fXrl1qgcnuULno3Evl07dFPqhwKyFbKtwI5ARZiy1RnifVZ7vdTklJifro6YPFaJPx8XHVljLEL3vMRSIRhoaG6OvrI51OY7FYqK+vp6mpSRU3y5Yg19NHstbKpUuXWFhYUEXcZPXLUChEMpmkuLiYiooKFVY7NTVFf3+/SvJxu92cPHkSi8XyQCRyIRaLW/l8PkpLS5dpGffjsNMLSnKub3RM6yOW7gV9JFxxcTHt7e189rOfZX5+nrffflvVAJf3lWNrYWGBGzduMDExQVVV1bIyBHLBHR0dJRaL4XK5KC4uVpVBNxN5wcCzoQ+3ymUakCn0fX19xONxSkpKaG9vV8WbYDGbc2RkhPfee4+PPvqIw4cP88QTTygmMDAwwJkzZ9A0jeeee07ZDrMHuUxXl17+e0kHetVY2mLtdjutra3L9urMPj/XPVbCg5aq1orVnitNVlvxrOzz9PZPaWLKFfGRyWSYnp6mv79fTcyioqKcDDyRSDAxMUEgEFAlZGWJ32wTnL5/9LbxbKzkt4jH4/T09BAIBCgqKlLjRmp1mUyGwsJCpUUAqh7Q7OwsAwMDNDU1ceLECfWesPkmFbPZTFlZGS6X674X7Ox+0pvF1hLRci+67jeLUjL96upq/H4/H374Ibdu3VLlEPQLjaYthjPLukWysqh+bsuM6YWFBTUPCgsLl4Uhb8a8zYtUemmz8nq9tLS0EIvF+PTTT/F4PBw5ckR1digUYmxsjK6uLt566y3S6TQvv/wyVVVV7N+/n+rqalVlb2xsTElLpaWlanUMBAIEAgHu3LnDxMSEauBss4is95DJZCgtLVXhfivFIctOjcViaseT27dvq8kmEzDm5+fVYJFhkPeT8q+XRPNV+t7MaIK1Pk9+CgoKcLlcnDhxQtXjnpmZ4dFHH11Ws3pkZIS5uTnOnDnDpUuXOHz4MAcPHlx2v+yKkl1dXdy+fZtYLIbVaqWxsZGWlhblpMw27dxvH0lfTygU4uLFi9y5c4doNEp1dTULCwuqAiWgqlMKIVQtoHfffReHw7GskuVmMQq9xhiJROju7iYYDCpHrd5EKc2Mua6Xf8vKyti9e7fa6UYfbrfR8SMXY1lSYy1Z0/J/n89HNBqlq6uLVCrF2NgYV69epbKykpqaGubm5hgaGqKzs5Pe3l5KS0t57rnnlKaUTqdV+YZXX32VoaEhjh8/js/n49ixYzQ2Ni4bWxvtm22XwGXHyWwz2YA9PT3s37+fcDisGN7s7Cy9vb3cuHGDS5cu4fF4+NrXvkZzc7NKdACU7Xl0dJRMJrOssl4wGKS/v5/R0VFVAVBvEtHbXb1eL7FYTO1cot8VKPsdZNal3IXl9u3b6vkFBQWqnKh8H2nrllL//diHN1Oy3cnQMxUpLctwuj179jA0NMRHH33E5OQk09PT1NTUqDroQ0NDDA8P88EHH/Duu+/idDoVA5fQLwyxWExldSYSCRwOB1VVVdTV1d1Fz0YWV32t7uvXr1NWVqais4LBIGNjY8CigCEXjnA4zOjoKFeuXKG5uZlDhw7hcrlWjGZaK7I1CXksGo2qGkX79u3D6/WqcbxaRqb+u8PhWOY4fpBY6f2zF1ohBB6Ph2QyidPpJJ1OEwgE6O3tVf6dhYUFbt++zZ07dxgZGcFms3Hs2DHq6+tVOV25f+5bb72lNnvYvXs3TU1NioHrnZ0bwbYx8GzpwGw2c+LECSoqKrh06RJXrlyhs7OTf/zHf1QSukwVjsfjvPzyy3i9Xvbv368SfWTYWTKZVJsAl5SU4HQ6lUNU1miORqN4vV6VZqwvmC8djg0NDQAqAmViYoLBwUG8Xi8Oh2NZKJim/S4RaXZ2lunpaWw2G6dOnVKp0kIIbt++jcPhUPWTNyNr9PcdevUbFhOvPvvZzzI2NkYsFiMUCvH222/z4YcfKg2qqKgIs9nMyZMnOXr0KAcOHGDPnj2Ul5er++mzK2Xd9ImJCdxuN9XV1SqFXL+ob2RCSqel3GFKlrCdn59Xxa7q6upUXfDXX38dn89Hc3MzwWCQJ554gvr6evbt24fL5coZybIeyOvldmLhcJiJiQnlsK2rq1u2ucX9vvOD0tjWspBm+6LcbjfFxcU89dRTSqt4/fXX2bdvn8qsvnDhAqlUij/4gz9QWlh5ebkSDsrKykin0xw/fhy3283+/ftpaGhYVjBss7TnbY8D10vgjz76qEpXvnHjBjdu3OD8+fPLHFLS+/7SSy9RVVXF3r17sVqtpFIpxcATiYSKRW5tbaWqqkpFbszOzirV1OPx4HQ6lfdeL8VZLBbFwGUt7YmJCYaGhigpKVFSuZT+NE1jZmaGnp4eotEoCwsL2Gw2HnvsMZX6L4Sgr69PFVIqLS1VKfMPE/RmhK1CNgM/ceKEKoY2ODjIu+++SyAQQIjFfIETJ07Q3NzME088oYpb6XdakufJzNdgMKjK9DY3N1NbW6sYuDSHbZR5y/eQ+QKxWIyuri5CoRANDQ00NzerkMqf/OQnvPHGGzQ0NNDS0kJbWxunTp2ipqaGffv2Kae4fJeNQvapjP6amprCarUqLSTX7kRreeeN2rvvRfO9tNVsx7Pb7cbtdvPUU0/R0NDAz3/+c1577TVGR0dJJpPcvHmTs2fPsm/fPr7xjW9QV1fHrl27lC8inU4re/ixY8fw+Xy0t7fjdruVf24zTVtbzsCzVzz9d/n/vn37+PKXv8zCwgKzs7NqQNhsNsrLyykvL2fXrl3KO69fBGBxEszNzTExMaG2epIMdGFhgZGRETRNo6GhQe1AXVNTw9GjR5UqKJ9psVhoamrCZDKpHcal3U8/6UymxQ2IDx48qDJL5ftle9plSr2+/vJ2ML0Hie22zxcUFFBSUsKRI0doamqiqqpKhXOaTItbgHk8Hnw+n4qg0C/k+iQQ6UzX18aR10kpfT0TMtdckCagU6dO0draytGjR4nFYsrHU1JSojI1PR4PlZWVajw2NTUpKS97fq2nP7JjmuUi1t3dTSKRUOG+Pp9v3eP4fsyH94v7kb6zz62oqEAIwTPPPKNKITQ0NFBZWalyOVpbW1XWq4TUoAAleUuNXZa70PuxNoq80d31A+3EiRM8+uijKpZYb5eWMdRyoMgJl92IgUCAoaGhZeUzAWVC8fl8tLa2Mjc3xw9/+EMOHTpES0sLTqdzWRanxWJR+xR2dnZy5coVlSatf54QgoaGBrVr/Frf917HDNw/pPRcWlrKE088gaYtbk6tT2fP3ndSJqTIOicygkXeS0aiCCHw+/00NzereiPr3dAgm2ZAVQ984YUXlMNQbsOnL0y1a9cuFf4qE7n0TkBpjtkIsn0LMzMz/OY3v6G3t1fVevH7/Wo7Q4m1PnczzE6bhezFVGbo7tq1ixdffJFoNEo4HMZisVBSUqJq60joFzqZvHXixIkVF/bNevdttYHDyhEL0uygt5Hpw3RyXSfT8QOBgKqBIeNjP/nkE4LBIF1dXczNzamBbzab8Xq9ymOtr2kBi/bvtrY2bDYb169fJxAIMDExwfj4uJKGVnuP+2kLA+tDLqdyNvQJW1IC0kcCTE5OMjY2xtTUFCMjI7jdbpqbm9VmHB0dHcTjcZxOJw0NDTQ0NOQs17BZ5grJjKWtPnvcS0d4rt82Qk+241JvYggGg9y4cYOFhQUVUZE9/tf6vHwa89mSuJ7pSu1LjhlZ1E7vIF5p7ut9ZA9qscobCTwbMiRsJQdfLg95KpWiv7+fkZERVQu4r6+P+fl5uru7KSkpUVtUyWiR1tZWHn/8cZqamlRqur4glc1m4/HHH2diYoIf/ehHDAwM0NPTg9frpa2tTRUZ0g9gfcdl06j/vlZboYH1QUqQwF3lBuQ2WDLho7u7mwsXLnDlyhXOnz/P4cOH+dKXvsTs7KxyXkYiEaqqqjhy5IjaTAMebF9K04TUNOXzsjdi0As6mxHvrb+XzO4cHx/n7bffprq6mr/+679Wtcz1uREPw3jWz2F9PkF21MxqkSR6+/5Go4FWwz0ZuBDCB/wTUAVkgO9pmvYfhBDlwD8DjUA/8Ieaps3eLwH3ksRXuy6bUUoJfHp6Wm2MID+yyH1xcTFNTU3EYjHC4TA+n4+mpia8Xq+yU2dLMLJWRltbG6lUivn5eW7cuEFFRYXaIeheUk8uBm7gwWMlyUfPdIUQaoLKBTwUCqn9ScPhMIWFhRw9elRFE8ia65vhjFrL9Wux526WpJcteAQCAW7dukVvby8Oh0OF+1ZVVS0TsPLJJLIerCaJ38+18vtWtMNaJPAU8G80TftECFECfCyEeAv4M+AdTdP+nRDiO8B3gH+7WYTdyxmit13Kc6UE3tfXR0lJCX6/n5aWFrxeLz6fD4/HQ3NzM42NjXR0dPD+++/T3t6uQoakupStksq6zl/+8pc5fvw4Fy5c4PLly7jdbmpqatTelIZUnV9YqS+kVKTv6/Lycpqbm7lz5w5Wq5VQKMSVK1dU9mNNTQ1/9md/RnV1tdodaiv7eS3j6kEVr+rs7OS73/0uiUSChoYG9u7dy9GjR1Udlod1zK/VCboStqKY2D0ZuKZpY8DY0v8LQoibQC3wEvDk0mk/AM6zAQa+3gGgvy6VSjE9Pc3k5CSFhYWUl5dTX1+Pz+dTdu7KykpVRtTv91NdXX2XgyjX4mEymfB6vQixWOA/HA4TjUYZHx9XESUSeoeGga3HvWziubQlm82G2+3G7/fzyCOPYLfbqaysVNdLIUDG+26HRrWatrrR5+e6ZzweJxqNEgwG1QYr2TV9NpOGfMH9WAW2W7O+Lxu4EKIROAz8FvAuMXc0TRsTQng2n7x7Q65yMoOto6ODzs5O9u7dS3NzM6dPn+bgwYPK2SNtnrt378bv96uY75VUbEBFuezbt09VNxwYGCAYDHLu3DlOnjy5bCdzg3nnP7L7qKamBo/HQ3t7Oy+99JKKSCkqKloWdSDH0MPYv9lhg1NTU3R3dzMwMABAS0sL3/rWt1RW8WalgxtYP9bMwIUQDuCnwLc1TZu/D9vQXwJ/Caw5xE53bc7j2TY6vd2pqKiI4uJiXC6Xsnvrq9BJ6AvLrPZMvR1MFuzxeDykUikikQiJROKu+xgDOr9wr/7QlsokyI9MDJN9K0NX13PvjWA7npn9HJlw1tzcTH19PRUVFXdVX3xYsRPeT6xRTSgEfgGc0TTt3y8duwU8uSR9VwPnNU1rW+0+x44d0y5fvrxhonPRLNOdf/CDHzA0NMSBAwdUqn11dbU6Tybd6KXl1aoD6p8lvcrxeFylFctaK/osvpXuZSA/kStqSC+NZtepvlc1yZ2IXCFv4XCYYDCozpGCkT755l7OewObAyHEx5qmHcs+vpYoFAH8J+CmZN5LeB34U+DfLf19bZNoXRdkaJVMTfd4PFRUVKy4XdNao16yPdOAKiKkTyIyBu/Dg7WYwB7W/ta/l9wYWF84K9d5D2tb7ASsxYRyEvgacE0I8enSsf+JRcb9X4QQ/xoYBF55IBSuETIF+bnnnlM78Mhqf7liydfjIZYTWy99GIWoHh7kQ1RBPiFXTX4D+YW1RKG8D6zUg5/bXHLWhpUGlNlsVpEDazl/Pc9cKVPNwM6Fvg9X0swe9n5ebU7d7zUGtg4Pnfgo7dQPMibbGLgGDBjIBzx0DHy19NbNgMG8H24Y/XtvGG2UP3joGPiDrDtgwIABA/mEh4qBGzZpAwY2D8Zcyn/8frnVDRgwYOAhgsHADRgwYGCHwmDgBgwYMLBDYTBwAwYMGNihMBi4AQMGDOxQGAzcgAEDBnYoDAZuwIABAzsUBgM3YMCAgR0Kg4EbMGDAwA6FwcANGDBgYIfCYOAGDBgwsENhMHADBgwY2KEwGLgBAwYM7FAYDNyAAQMGdigMBm7AgAEDOxRirbuzb8rDhJgCwkBgyx66flRi0LmZ2Al07gQawaBzs7ET6GzQNM2dfXBLGTiAEOKypmnHtvSh64BB5+ZiJ9C5E2gEg87Nxk6hMxcME4oBAwYM7FAYDNyAAQMGdii2g4F/bxueuR4YdG4udgKdO4FGMOjcbOwUOu/CltvADRgwYMDA5sAwoRgwYMDADsWWMXAhxOeFELeEEL1CiO9s1XPvBSGETwhxTghxUwhxXQjxraXj5UKIt4QQPUt/y7abVgAhhFkIcUUI8Yul73lHpxDCJYT4iRCia6ldP5OndP4PS33eKYT4kRCiOB/oFEL8ZyHEpBCiU3dsRbqEEH+3NK9uCSGe22Y6/9elfu8QQvxcCOHKRzp1v/2PQghNCFG53XSuB1vCwIUQZuD/AL4A7AH+lRBiz1Y8ew1IAf9G07TdwAngv12i7TvAO5qmtQDvLH3PB3wLuKn7no90/gfg/9M0rR04yCK9eUWnEKIW+O+BY5qm7QPMwB+TH3R+H/h81rGcdC2N1T8G9i5d838uzbftovMtYJ+maQeAbuDv8pROhBA+4FlgUHdsO+m8b2yVBH4c6NU0rU/TtATwY+ClLXr2qtA0bUzTtE+W/l9gkdnUskjfD5ZO+wHw8rYQqIMQog74IvAfdYfzik4hhBN4HPhPAJqmJTRNmyPP6FxCAWAVQhQANmCUPKBT07T3gJmswyvR9RLwY03T4pqm3QF6WZxv20KnpmlnNU1LLX39EKjLRzqX8L8DfwvoHYHbRud6sFUMvBYY0n0fXjqWVxBCNAKHgd8CXk3TxmCRyQOebSRN4rssDriM7li+0dkMTAH/95Kp5z8KIezkGZ2apo0A/xuL0tcYENQ07Sx5RqcOK9GVz3Prz4FfLf2fV3QKIV4ERjRNu5r1U17ReS9sFQMXOY7lVfiLEMIB/BT4tqZp89tNTzaEEM8Dk5qmfbzdtNwDBcAR4P/SNO0wi6UT8sGsswxLNuSXgCagBrALIb66vVStC3k5t4QQf8+iefJVeSjHadtCpxDCBvw98D/n+jnHsW1vz5WwVQx8GPDpvtexqK7mBYQQhSwy71c1TfvZ0uEJIUT10u/VwOR20beEk8CLQoh+Fk1QTwsh/l/yj85hYFjTtN8uff8Jiww93+h8BrijadqUpmlJ4GfAZ8k/OiVWoivv5pYQ4k+B54H/RvtdnHI+0elnceG+ujSf6oBPhBBV5Bed98RWMfBLQIsQokkIUcSik+D1LXr2qhBCCBbttTc1Tfv3up9eB/506f8/BV7batr00DTt7zRNq9M0rZHF9ntX07Svkn90jgNDQoi2pUOfA26QZ3SyaDo5IYSwLY2Bz7Ho/8g3OiVWout14I+FEBYhRBPQAny0DfQBi9FmwL8FXtQ0LaL7KW/o1DTtmqZpHk3TGpfm0zBwZGns5g2da4KmaVvyAU6z6JW+Dfz9Vj13DXQ9xqKK1AF8uvQ5DVSw6O3vWfpbvt206mh+EvjF0v95RydwCLi81Kb/FSjLUzr/F6AL6AT+H8CSD3QCP2LRLp9kkbn869XoYtEccBu4BXxhm+nsZdGGLOfSP+QjnVm/9wOV203nej5GJqYBAwYM7FAYmZgGDBgwsENhMHADBgwY2KEwGLgBAwYM7FAYDNyAAQMGdigMBm7AgAEDOxQGAzdgwICBHQqDgRswYMDADoXBwA0YMGBgh+L/B0PPaW9qN4KFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_tensor_as_image(train_dataset[6][0])\n",
    "show_tensor_as_image(train_dataset[50][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de dos datos de salida: (correspondiente a los de entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\partial _ { \\mu } ( F ^ { \\mu \\nu } - e j ^ { \\mu } x ^ { \\nu } ) = 0 .\n",
      "\\theta \\epsilon ^ { i } = \\zeta ^ { i } \\, ; \\qquad \\theta \\zeta ^ { i } = \\epsilon ^ { i } \\, ; \\qquad \\theta \\eta ^ { i } = - \\eta ^ { i } \\, .\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[6][1])\n",
    "print(train_dataset[50][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Definición, Entrenamiento y Evaluación  \n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.I Arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************************************\n",
    "# **********************  Architecture  ******************************\n",
    "# ********************************************************************\n",
    "\n",
    "model = Model(\n",
    "out_size=len(vocabulary),\n",
    "enc_out_dim=512,\n",
    "emb_size=80,\n",
    "dec_rnn_h=512,\n",
    "dropout=drop_out\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el código del modelo completo: `/src/architecture/model.py` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.II Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************************************\n",
    "# **********************  Training  **********************************\n",
    "# ********************************************************************\n",
    "\n",
    "# Hyper parameters for training \n",
    "init_epoch = 1\n",
    "\n",
    "# For epsilon calculation\n",
    "decay_k = 1 #default\n",
    "sample_method = \"inv_sigmoid\" #default [\"exp\", \"inv_sigmoid\", \"teacher_forcing\")\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader (\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    #TODO how collate works?\n",
    "    # https://discuss.pytorch.org/t/how-to-create-a-dataloader-with-variable-size-input/8278\n",
    "    collate_fn=partial(collate_fn, vocabulary.token_id_dic),\n",
    "    pin_memory=False, # It must be False (no GPU): https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723\n",
    "    #shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=partial(collate_fn, vocabulary.token_id_dic)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    \"min\",\n",
    "    factor=0.5, # float default - Learning rate decay rate\n",
    "    patience=3, # int default - Learning rate decay patience\n",
    "    verbose=True,\n",
    "    min_lr=3e-5) # default 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to save results\n",
    "training_losses = []\n",
    "valid_losses = []\n",
    "total_step = 0\n",
    "best_valid_loss = 1e18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++ Training initialized +++++++++++++++\n",
      "[Train] Epoch 1/5 Step 10/7528 Loss 5.413578\n",
      "[Train] Epoch 1/5 Step 20/7528 Loss 4.893776\n",
      "[Train] Epoch 1/5 Step 30/7528 Loss 4.630878\n",
      "[Train] Epoch 1/5 Step 40/7528 Loss 4.477638\n",
      "[Train] Epoch 1/5 Step 50/7528 Loss 4.405375\n",
      "[Train] Epoch 1/5 Step 60/7528 Loss 4.358254\n",
      "[Train] Epoch 1/5 Step 70/7528 Loss 4.294891\n",
      "[Train] Epoch 1/5 Step 80/7528 Loss 4.264323\n",
      "[Train] Epoch 1/5 Step 90/7528 Loss 4.227040\n",
      "[Train] Epoch 1/5 Step 100/7528 Loss 4.207898\n",
      "[Train] Epoch 1/5 Step 110/7528 Loss 4.186956\n",
      "[Train] Epoch 1/5 Step 120/7528 Loss 4.165333\n",
      "[Train] Epoch 1/5 Step 130/7528 Loss 4.128827\n",
      "[Train] Epoch 1/5 Step 140/7528 Loss 4.100134\n",
      "[Train] Epoch 1/5 Step 150/7528 Loss 4.066745\n",
      "[Train] Epoch 1/5 Step 160/7528 Loss 4.042028\n",
      "[Train] Epoch 1/5 Step 170/7528 Loss 3.995395\n",
      "[Train] Epoch 1/5 Step 180/7528 Loss 3.973333\n",
      "[Train] Epoch 1/5 Step 190/7528 Loss 3.940873\n",
      "[Train] Epoch 1/5 Step 200/7528 Loss 3.904271\n",
      "[Train] Epoch 1/5 Step 210/7528 Loss 3.866371\n",
      "[Train] Epoch 1/5 Step 220/7528 Loss 3.867933\n",
      "[Train] Epoch 1/5 Step 230/7528 Loss 3.844539\n",
      "[Train] Epoch 1/5 Step 240/7528 Loss 3.821771\n",
      "[Train] Epoch 1/5 Step 250/7528 Loss 3.796729\n",
      "[Train] Epoch 1/5 Step 260/7528 Loss 3.783910\n",
      "[Train] Epoch 1/5 Step 270/7528 Loss 3.763359\n",
      "[Train] Epoch 1/5 Step 280/7528 Loss 3.745626\n",
      "[Train] Epoch 1/5 Step 290/7528 Loss 3.734407\n",
      "[Train] Epoch 1/5 Step 300/7528 Loss 3.717425\n",
      "[Train] Epoch 1/5 Step 310/7528 Loss 3.702013\n",
      "[Train] Epoch 1/5 Step 320/7528 Loss 3.692156\n",
      "[Train] Epoch 1/5 Step 330/7528 Loss 3.677265\n",
      "[Train] Epoch 1/5 Step 340/7528 Loss 3.667343\n",
      "[Train] Epoch 1/5 Step 350/7528 Loss 3.654177\n",
      "[Train] Epoch 1/5 Step 360/7528 Loss 3.635399\n",
      "[Train] Epoch 1/5 Step 370/7528 Loss 3.620895\n",
      "[Train] Epoch 1/5 Step 380/7528 Loss 3.614026\n",
      "[Train] Epoch 1/5 Step 390/7528 Loss 3.600147\n",
      "[Train] Epoch 1/5 Step 400/7528 Loss 3.590620\n",
      "[Train] Epoch 1/5 Step 410/7528 Loss 3.584567\n",
      "[Train] Epoch 1/5 Step 420/7528 Loss 3.566528\n",
      "[Train] Epoch 1/5 Step 430/7528 Loss 3.560480\n",
      "[Train] Epoch 1/5 Step 440/7528 Loss 3.547340\n",
      "[Train] Epoch 1/5 Step 450/7528 Loss 3.538650\n",
      "[Train] Epoch 1/5 Step 460/7528 Loss 3.527594\n",
      "[Train] Epoch 1/5 Step 470/7528 Loss 3.516494\n",
      "[Train] Epoch 1/5 Step 480/7528 Loss 3.509621\n",
      "[Train] Epoch 1/5 Step 490/7528 Loss 3.496893\n",
      "[Train] Epoch 1/5 Step 500/7528 Loss 3.492815\n",
      "[Train] Epoch 1/5 Step 510/7528 Loss 3.483365\n",
      "[Train] Epoch 1/5 Step 520/7528 Loss 3.474664\n",
      "[Train] Epoch 1/5 Step 530/7528 Loss 3.469170\n",
      "[Train] Epoch 1/5 Step 540/7528 Loss 3.462211\n",
      "[Train] Epoch 1/5 Step 550/7528 Loss 3.454306\n",
      "[Train] Epoch 1/5 Step 560/7528 Loss 3.447697\n",
      "[Train] Epoch 1/5 Step 570/7528 Loss 3.441618\n",
      "[Train] Epoch 1/5 Step 580/7528 Loss 3.433714\n",
      "[Train] Epoch 1/5 Step 590/7528 Loss 3.422448\n",
      "[Train] Epoch 1/5 Step 600/7528 Loss 3.415104\n",
      "[Train] Epoch 1/5 Step 610/7528 Loss 3.407710\n",
      "[Train] Epoch 1/5 Step 620/7528 Loss 3.396961\n",
      "[Train] Epoch 1/5 Step 630/7528 Loss 3.386897\n",
      "[Train] Epoch 1/5 Step 640/7528 Loss 3.382490\n",
      "[Train] Epoch 1/5 Step 650/7528 Loss 3.375878\n",
      "[Train] Epoch 1/5 Step 660/7528 Loss 3.367295\n",
      "[Train] Epoch 1/5 Step 670/7528 Loss 3.363836\n",
      "[Train] Epoch 1/5 Step 680/7528 Loss 3.354599\n",
      "[Train] Epoch 1/5 Step 690/7528 Loss 3.352085\n",
      "[Train] Epoch 1/5 Step 700/7528 Loss 3.346755\n",
      "[Train] Epoch 1/5 Step 710/7528 Loss 3.338324\n",
      "[Train] Epoch 1/5 Step 720/7528 Loss 3.330806\n",
      "[Train] Epoch 1/5 Step 730/7528 Loss 3.323892\n",
      "[Train] Epoch 1/5 Step 740/7528 Loss 3.313468\n",
      "[Train] Epoch 1/5 Step 750/7528 Loss 3.307838\n",
      "[Train] Epoch 1/5 Step 760/7528 Loss 3.302667\n",
      "[Train] Epoch 1/5 Step 770/7528 Loss 3.297717\n",
      "[Train] Epoch 1/5 Step 780/7528 Loss 3.292883\n",
      "[Train] Epoch 1/5 Step 790/7528 Loss 3.287495\n",
      "[Train] Epoch 1/5 Step 800/7528 Loss 3.281205\n",
      "[Train] Epoch 1/5 Step 810/7528 Loss 3.276006\n",
      "[Train] Epoch 1/5 Step 820/7528 Loss 3.270364\n",
      "[Train] Epoch 1/5 Step 830/7528 Loss 3.263493\n",
      "[Train] Epoch 1/5 Step 840/7528 Loss 3.260061\n",
      "[Train] Epoch 1/5 Step 850/7528 Loss 3.254215\n",
      "[Train] Epoch 1/5 Step 860/7528 Loss 3.249360\n",
      "[Train] Epoch 1/5 Step 870/7528 Loss 3.245206\n",
      "[Train] Epoch 1/5 Step 880/7528 Loss 3.243731\n",
      "[Train] Epoch 1/5 Step 890/7528 Loss 3.239254\n",
      "[Train] Epoch 1/5 Step 900/7528 Loss 3.232131\n",
      "[Train] Epoch 1/5 Step 910/7528 Loss 3.226526\n",
      "[Train] Epoch 1/5 Step 920/7528 Loss 3.223795\n",
      "[Train] Epoch 1/5 Step 930/7528 Loss 3.219375\n",
      "[Train] Epoch 1/5 Step 940/7528 Loss 3.216234\n",
      "[Train] Epoch 1/5 Step 950/7528 Loss 3.210845\n",
      "[Train] Epoch 1/5 Step 960/7528 Loss 3.208140\n",
      "[Train] Epoch 1/5 Step 970/7528 Loss 3.203823\n",
      "[Train] Epoch 1/5 Step 980/7528 Loss 3.198763\n",
      "[Train] Epoch 1/5 Step 990/7528 Loss 3.196663\n",
      "[Train] Epoch 1/5 Step 1000/7528 Loss 3.194060\n",
      "[Train] Epoch 1/5 Step 1010/7528 Loss 3.193236\n",
      "[Train] Epoch 1/5 Step 1020/7528 Loss 3.190441\n",
      "[Train] Epoch 1/5 Step 1030/7528 Loss 3.188927\n",
      "[Train] Epoch 1/5 Step 1040/7528 Loss 3.183182\n",
      "[Train] Epoch 1/5 Step 1050/7528 Loss 3.179898\n",
      "[Train] Epoch 1/5 Step 1060/7528 Loss 3.175127\n",
      "[Train] Epoch 1/5 Step 1070/7528 Loss 3.171385\n",
      "[Train] Epoch 1/5 Step 1080/7528 Loss 3.168703\n",
      "[Train] Epoch 1/5 Step 1090/7528 Loss 3.166938\n",
      "[Train] Epoch 1/5 Step 1100/7528 Loss 3.164494\n",
      "[Train] Epoch 1/5 Step 1110/7528 Loss 3.160029\n",
      "[Train] Epoch 1/5 Step 1120/7528 Loss 3.156082\n",
      "[Train] Epoch 1/5 Step 1130/7528 Loss 3.151651\n",
      "[Train] Epoch 1/5 Step 1140/7528 Loss 3.149133\n",
      "[Train] Epoch 1/5 Step 1150/7528 Loss 3.147805\n",
      "[Train] Epoch 1/5 Step 1160/7528 Loss 3.146838\n",
      "[Train] Epoch 1/5 Step 1170/7528 Loss 3.142911\n",
      "[Train] Epoch 1/5 Step 1180/7528 Loss 3.139202\n",
      "[Train] Epoch 1/5 Step 1190/7528 Loss 3.137849\n",
      "[Train] Epoch 1/5 Step 1200/7528 Loss 3.134260\n",
      "[Train] Epoch 1/5 Step 1210/7528 Loss 3.129435\n",
      "[Train] Epoch 1/5 Step 1220/7528 Loss 3.125788\n",
      "[Train] Epoch 1/5 Step 1230/7528 Loss 3.124130\n",
      "[Train] Epoch 1/5 Step 1240/7528 Loss 3.121622\n",
      "[Train] Epoch 1/5 Step 1250/7528 Loss 3.118327\n",
      "[Train] Epoch 1/5 Step 1260/7528 Loss 3.114017\n",
      "[Train] Epoch 1/5 Step 1270/7528 Loss 3.112450\n",
      "[Train] Epoch 1/5 Step 1280/7528 Loss 3.108535\n",
      "[Train] Epoch 1/5 Step 1290/7528 Loss 3.103945\n",
      "[Train] Epoch 1/5 Step 1300/7528 Loss 3.101853\n",
      "[Train] Epoch 1/5 Step 1310/7528 Loss 3.099933\n",
      "[Train] Epoch 1/5 Step 1320/7528 Loss 3.098006\n",
      "[Train] Epoch 1/5 Step 1330/7528 Loss 3.095141\n",
      "[Train] Epoch 1/5 Step 1340/7528 Loss 3.093162\n",
      "[Train] Epoch 1/5 Step 1350/7528 Loss 3.090704\n",
      "[Train] Epoch 1/5 Step 1360/7528 Loss 3.088422\n",
      "[Train] Epoch 1/5 Step 1370/7528 Loss 3.084520\n",
      "[Train] Epoch 1/5 Step 1380/7528 Loss 3.081898\n",
      "[Train] Epoch 1/5 Step 1390/7528 Loss 3.078430\n",
      "[Train] Epoch 1/5 Step 1400/7528 Loss 3.076711\n",
      "[Train] Epoch 1/5 Step 1410/7528 Loss 3.073319\n",
      "[Train] Epoch 1/5 Step 1420/7528 Loss 3.070015\n",
      "[Train] Epoch 1/5 Step 1430/7528 Loss 3.066172\n",
      "[Train] Epoch 1/5 Step 1440/7528 Loss 3.062735\n",
      "[Train] Epoch 1/5 Step 1450/7528 Loss 3.059044\n",
      "[Train] Epoch 1/5 Step 1460/7528 Loss 3.056877\n",
      "[Train] Epoch 1/5 Step 1470/7528 Loss 3.054134\n",
      "[Train] Epoch 1/5 Step 1480/7528 Loss 3.051289\n",
      "[Train] Epoch 1/5 Step 1490/7528 Loss 3.049373\n",
      "[Train] Epoch 1/5 Step 1500/7528 Loss 3.045444\n",
      "[Train] Epoch 1/5 Step 1510/7528 Loss 3.043230\n",
      "[Train] Epoch 1/5 Step 1520/7528 Loss 3.040717\n",
      "[Train] Epoch 1/5 Step 1530/7528 Loss 3.038367\n",
      "[Train] Epoch 1/5 Step 1540/7528 Loss 3.037648\n",
      "[Train] Epoch 1/5 Step 1550/7528 Loss 3.035446\n",
      "[Train] Epoch 1/5 Step 1560/7528 Loss 3.032440\n",
      "[Train] Epoch 1/5 Step 1570/7528 Loss 3.032069\n",
      "[Train] Epoch 1/5 Step 1580/7528 Loss 3.029448\n",
      "[Train] Epoch 1/5 Step 1590/7528 Loss 3.028491\n",
      "[Train] Epoch 1/5 Step 1600/7528 Loss 3.028217\n",
      "[Train] Epoch 1/5 Step 1610/7528 Loss 3.027407\n",
      "[Train] Epoch 1/5 Step 1620/7528 Loss 3.025882\n",
      "[Train] Epoch 1/5 Step 1630/7528 Loss 3.024320\n",
      "[Train] Epoch 1/5 Step 1640/7528 Loss 3.022371\n",
      "[Train] Epoch 1/5 Step 1650/7528 Loss 3.020031\n",
      "[Train] Epoch 1/5 Step 1660/7528 Loss 3.017016\n",
      "[Train] Epoch 1/5 Step 1670/7528 Loss 3.015009\n",
      "[Train] Epoch 1/5 Step 1680/7528 Loss 3.011650\n",
      "[Train] Epoch 1/5 Step 1690/7528 Loss 3.009951\n",
      "[Train] Epoch 1/5 Step 1700/7528 Loss 3.006841\n",
      "[Train] Epoch 1/5 Step 1710/7528 Loss 3.004347\n",
      "[Train] Epoch 1/5 Step 1720/7528 Loss 3.002299\n",
      "[Train] Epoch 1/5 Step 1730/7528 Loss 3.001508\n",
      "[Train] Epoch 1/5 Step 1740/7528 Loss 2.999486\n",
      "[Train] Epoch 1/5 Step 1750/7528 Loss 2.997012\n",
      "[Train] Epoch 1/5 Step 1760/7528 Loss 2.995625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 1/5 Step 1770/7528 Loss 2.993692\n",
      "[Train] Epoch 1/5 Step 1780/7528 Loss 2.992780\n",
      "[Train] Epoch 1/5 Step 1790/7528 Loss 2.991254\n",
      "[Train] Epoch 1/5 Step 1800/7528 Loss 2.988991\n",
      "[Train] Epoch 1/5 Step 1810/7528 Loss 2.987697\n",
      "[Train] Epoch 1/5 Step 1820/7528 Loss 2.986625\n",
      "[Train] Epoch 1/5 Step 1830/7528 Loss 2.984322\n",
      "[Train] Epoch 1/5 Step 1840/7528 Loss 2.982423\n",
      "[Train] Epoch 1/5 Step 1850/7528 Loss 2.980699\n",
      "[Train] Epoch 1/5 Step 1860/7528 Loss 2.978636\n",
      "[Train] Epoch 1/5 Step 1870/7528 Loss 2.976855\n",
      "[Train] Epoch 1/5 Step 1880/7528 Loss 2.974466\n",
      "[Train] Epoch 1/5 Step 1890/7528 Loss 2.972974\n",
      "[Train] Epoch 1/5 Step 1900/7528 Loss 2.971567\n",
      "[Train] Epoch 1/5 Step 1910/7528 Loss 2.970009\n",
      "[Train] Epoch 1/5 Step 1920/7528 Loss 2.969070\n",
      "[Train] Epoch 1/5 Step 1930/7528 Loss 2.967395\n",
      "[Train] Epoch 1/5 Step 1940/7528 Loss 2.965414\n",
      "[Train] Epoch 1/5 Step 1950/7528 Loss 2.964785\n",
      "[Train] Epoch 1/5 Step 1960/7528 Loss 2.962955\n",
      "[Train] Epoch 1/5 Step 1970/7528 Loss 2.960827\n",
      "[Train] Epoch 1/5 Step 1980/7528 Loss 2.960685\n",
      "[Train] Epoch 1/5 Step 1990/7528 Loss 2.959699\n",
      "[Train] Epoch 1/5 Step 2000/7528 Loss 2.958562\n",
      "[Train] Epoch 1/5 Step 2010/7528 Loss 2.956065\n",
      "[Train] Epoch 1/5 Step 2020/7528 Loss 2.954514\n",
      "[Train] Epoch 1/5 Step 2030/7528 Loss 2.953440\n",
      "[Train] Epoch 1/5 Step 2040/7528 Loss 2.951965\n",
      "[Train] Epoch 1/5 Step 2050/7528 Loss 2.950345\n",
      "[Train] Epoch 1/5 Step 2060/7528 Loss 2.948172\n",
      "[Train] Epoch 1/5 Step 2070/7528 Loss 2.945849\n",
      "[Train] Epoch 1/5 Step 2080/7528 Loss 2.944051\n",
      "[Train] Epoch 1/5 Step 2090/7528 Loss 2.943250\n",
      "[Train] Epoch 1/5 Step 2100/7528 Loss 2.942348\n",
      "[Train] Epoch 1/5 Step 2110/7528 Loss 2.940906\n",
      "[Train] Epoch 1/5 Step 2120/7528 Loss 2.939928\n",
      "[Train] Epoch 1/5 Step 2130/7528 Loss 2.939101\n",
      "[Train] Epoch 1/5 Step 2140/7528 Loss 2.937480\n",
      "[Train] Epoch 1/5 Step 2150/7528 Loss 2.936694\n",
      "[Train] Epoch 1/5 Step 2160/7528 Loss 2.935902\n",
      "[Train] Epoch 1/5 Step 2170/7528 Loss 2.935037\n",
      "[Train] Epoch 1/5 Step 2180/7528 Loss 2.933321\n",
      "[Train] Epoch 1/5 Step 2190/7528 Loss 2.934357\n",
      "[Train] Epoch 1/5 Step 2200/7528 Loss 2.931802\n",
      "[Train] Epoch 1/5 Step 2210/7528 Loss 2.931478\n",
      "[Train] Epoch 1/5 Step 2220/7528 Loss 2.930802\n",
      "[Train] Epoch 1/5 Step 2230/7528 Loss 2.929623\n",
      "[Train] Epoch 1/5 Step 2240/7528 Loss 2.927866\n",
      "[Train] Epoch 1/5 Step 2250/7528 Loss 2.925967\n",
      "[Train] Epoch 1/5 Step 2260/7528 Loss 2.923993\n",
      "[Train] Epoch 1/5 Step 2270/7528 Loss 2.922903\n",
      "[Train] Epoch 1/5 Step 2280/7528 Loss 2.922178\n",
      "[Train] Epoch 1/5 Step 2290/7528 Loss 2.923031\n",
      "[Train] Epoch 1/5 Step 2300/7528 Loss 2.922129\n",
      "[Train] Epoch 1/5 Step 2310/7528 Loss 2.922770\n",
      "[Train] Epoch 1/5 Step 2320/7528 Loss 2.921631\n",
      "[Train] Epoch 1/5 Step 2330/7528 Loss 2.921211\n",
      "[Train] Epoch 1/5 Step 2340/7528 Loss 2.920351\n",
      "[Train] Epoch 1/5 Step 2350/7528 Loss 2.919236\n",
      "[Train] Epoch 1/5 Step 2360/7528 Loss 2.919164\n",
      "[Train] Epoch 1/5 Step 2370/7528 Loss 2.917098\n",
      "[Train] Epoch 1/5 Step 2380/7528 Loss 2.915792\n",
      "[Train] Epoch 1/5 Step 2390/7528 Loss 2.915938\n",
      "[Train] Epoch 1/5 Step 2400/7528 Loss 2.914443\n",
      "[Train] Epoch 1/5 Step 2410/7528 Loss 2.914207\n",
      "[Train] Epoch 1/5 Step 2420/7528 Loss 2.913642\n",
      "[Train] Epoch 1/5 Step 2430/7528 Loss 2.912766\n",
      "[Train] Epoch 1/5 Step 2440/7528 Loss 2.912434\n",
      "[Train] Epoch 1/5 Step 2450/7528 Loss 2.911362\n",
      "[Train] Epoch 1/5 Step 2460/7528 Loss 2.909868\n",
      "[Train] Epoch 1/5 Step 2470/7528 Loss 2.909484\n",
      "[Train] Epoch 1/5 Step 2480/7528 Loss 2.908402\n",
      "[Train] Epoch 1/5 Step 2490/7528 Loss 2.906962\n",
      "[Train] Epoch 1/5 Step 2500/7528 Loss 2.905699\n",
      "[Train] Epoch 1/5 Step 2510/7528 Loss 2.904593\n",
      "[Train] Epoch 1/5 Step 2520/7528 Loss 2.903444\n",
      "[Train] Epoch 1/5 Step 2530/7528 Loss 2.903128\n",
      "[Train] Epoch 1/5 Step 2540/7528 Loss 2.901082\n",
      "[Train] Epoch 1/5 Step 2550/7528 Loss 2.900588\n",
      "[Train] Epoch 1/5 Step 2560/7528 Loss 2.899349\n",
      "[Train] Epoch 1/5 Step 2570/7528 Loss 2.899218\n",
      "[Train] Epoch 1/5 Step 2580/7528 Loss 2.898116\n",
      "[Train] Epoch 1/5 Step 2590/7528 Loss 2.898055\n",
      "[Train] Epoch 1/5 Step 2600/7528 Loss 2.897217\n",
      "[Train] Epoch 1/5 Step 2610/7528 Loss 2.896488\n",
      "[Train] Epoch 1/5 Step 2620/7528 Loss 2.895935\n",
      "[Train] Epoch 1/5 Step 2630/7528 Loss 2.896029\n",
      "[Train] Epoch 1/5 Step 2640/7528 Loss 2.894816\n",
      "[Train] Epoch 1/5 Step 2650/7528 Loss 2.894407\n",
      "[Train] Epoch 1/5 Step 2660/7528 Loss 2.893570\n",
      "[Train] Epoch 1/5 Step 2670/7528 Loss 2.893995\n",
      "[Train] Epoch 1/5 Step 2680/7528 Loss 2.893842\n",
      "[Train] Epoch 1/5 Step 2690/7528 Loss 2.892091\n",
      "[Train] Epoch 1/5 Step 2700/7528 Loss 2.891142\n",
      "[Train] Epoch 1/5 Step 2710/7528 Loss 2.889390\n",
      "[Train] Epoch 1/5 Step 2720/7528 Loss 2.887369\n",
      "[Train] Epoch 1/5 Step 2730/7528 Loss 2.887562\n",
      "[Train] Epoch 1/5 Step 2740/7528 Loss 2.887430\n",
      "[Train] Epoch 1/5 Step 2750/7528 Loss 2.886566\n",
      "[Train] Epoch 1/5 Step 2760/7528 Loss 2.885858\n",
      "[Train] Epoch 1/5 Step 2770/7528 Loss 2.884899\n",
      "[Train] Epoch 1/5 Step 2780/7528 Loss 2.883441\n",
      "[Train] Epoch 1/5 Step 2790/7528 Loss 2.881339\n",
      "[Train] Epoch 1/5 Step 2800/7528 Loss 2.879565\n",
      "[Train] Epoch 1/5 Step 2810/7528 Loss 2.878437\n",
      "[Train] Epoch 1/5 Step 2820/7528 Loss 2.878145\n",
      "[Train] Epoch 1/5 Step 2830/7528 Loss 2.876784\n",
      "[Train] Epoch 1/5 Step 2840/7528 Loss 2.875466\n",
      "[Train] Epoch 1/5 Step 2850/7528 Loss 2.874382\n",
      "[Train] Epoch 1/5 Step 2860/7528 Loss 2.872463\n",
      "[Train] Epoch 1/5 Step 2870/7528 Loss 2.871436\n",
      "[Train] Epoch 1/5 Step 2880/7528 Loss 2.870019\n",
      "[Train] Epoch 1/5 Step 2890/7528 Loss 2.869072\n"
     ]
    }
   ],
   "source": [
    "# For profiling\n",
    "logger = TrainingLogger(print_freq=10)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    step_losses = []\n",
    "    step = 1\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    loader_len = len(train_loader)\n",
    "    for imgs_batch, tgt4training_batch, tgt4loss_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Epsilon\n",
    "        #epsilon = cal_epsilon(decay_k, total_step, sample_method)\n",
    "\n",
    "        # Prediction\n",
    "        logits = model(imgs_batch, tgt4training_batch, 1.)\n",
    "\n",
    "        # Compute Loss\n",
    "        step_loss = cal_loss(logits, tgt4loss_batch)\n",
    "            \n",
    "        # Add loss\n",
    "        step_losses.append(step_loss.item())\n",
    "\n",
    "        # Print results\n",
    "        logger.log_train_step(epoch+1, epochs, step, loader_len, statistics.mean(step_losses))\n",
    "\n",
    "        # Updates\n",
    "        step_loss.backward()\n",
    "        clip_grad_norm_(model.parameters(),clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        step += 1\n",
    "        total_step += 1\n",
    "        \n",
    "    training_losses.append(statistics.mean(step_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.III Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Validation\n",
    "    model.eval()\n",
    "    step_losses = []\n",
    "    with torch.no_grad(): # This disable any gradient calculation (better performance)\n",
    "        for imgs_batch, tgt4training, tgt4loss_batch in valid_loader:\n",
    "\n",
    "            # Epsilon\n",
    "            #epsilon = cal_epsilon(decay_k, total_step, sample_method)\n",
    "\n",
    "            # Prediction\n",
    "            pred = model(imgs_batch, tgt4training, 1.)\n",
    "\n",
    "            # Compute loss\n",
    "            step_loss = cal_loss(pred, tgt4loss_batch)\n",
    "            step_losses.append(step_loss.item()) \n",
    "\n",
    "            # Print results\n",
    "            logger.log_val_step(epoch+1, epochs, statistics.mean(step_losses))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Best validation loss\n",
    "    valid_loss = statistics.mean(step_losses)\n",
    "    if valid_loss < best_valid_loss: #best valid loss\n",
    "        best_valid_loss = valid_loss\n",
    "        save_model(\"best_ckpt\", model)\n",
    "\n",
    "    # Scheduler\n",
    "    lr_scheduler.step(valid_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    # Save model checkpoint ckpt-e{epoch}\n",
    "    save_model(f\"ckpt-e{epoch+1}-vl{valid_loss:.4f}\", model)\n",
    "\n",
    "    # Print results\n",
    "    logger.log_epoch(epoch+1, epochs, statistics.mean(training_losses), statistics.mean(valid_losses))\n",
    "\n",
    "del logger\n",
    "\n",
    "# ********************************************************************\n",
    "# **********************  Testing  ***********************************\n",
    "# ********************************************************************\n",
    "\n",
    "    latex_generator = LatexGenerator(model, vocabulary)\n",
    "\n",
    "    # Loader\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        collate_fn=partial(collate_fn_batch_size_one, vocabulary.token_id_dic)\n",
    "    )\n",
    "\n",
    "    # Save testing data\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    for img, formula in test_loader:\n",
    "        try:\n",
    "            prediction = latex_generator(img)[0]\n",
    "            targets.append(formula)\n",
    "            predictions.append(prediction)\n",
    "        except RuntimeError:\n",
    "            break\n",
    "    \n",
    "    SAVE_TEST_DATA(F\"RES_{EPOCHS}_{BATCH_SIZE}_{INT(NUM_DATA_TRAIN/1000)}K_{INT(NUM_DATA_VAL/1000)}K_{INT(NUM_DATA_TEST/1000)}K\", TARGETS, PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset._pairs[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
